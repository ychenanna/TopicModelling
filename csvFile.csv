Amino,,,,
"  Amino – A Next Generation Layered Computing Infrastructure for Crypto Economy
Version 0.6.1

1 Executive Summary
 Amino is a next-generation layered computing infrastructure for cryptoeconomy. Amino enables on-demand, cost-effective, commercial-grade high performance distributed computing by encouraging owners of high-performance computer hardware to contribute their idle computing resources to various computing tasks and applications.
 In the near future, more and more industries, such as AI, IoT, AR/VR, 5G and blockchain, will require distributed computing networks. These networks need to have low latency, enhanced security, resilience, scalability and efficiency. The old-generation decentralised distributed computing networks, such as Golem and SONM, use peer-to-peer marketplaces to enable computing consumers (“requestors”) to rent resources from other individual contributors’ (“providers”) machines, but these resource sharing models within the marketplace leads to poor experiences for both contributors and consumers of those resources. No matter how their technologies improve, the oldgeneration networks cannot satisfy the needs of either the contributors or consumers because of fundamental flaws in their economic model. Amino provides a unique economic model that both meets the growing demand for distributed computing and creates a fair reward system in order to encourage providers to share their idle computing resources.
 Amino enables computing resources to be shared via a decentralised, distributed computing network based on commercial level technologies that were researched and implemented by the Amino team since 2010. Amino provides a more stable, highly-efficient and safe system architecture for sharing computing resources, called the Amino OS (operating system) – a kinde of TEE OS. In addition, intelligent modules will integrate both the Amino OS and the innovative decentralised computing ecosystem of Amino to enable Amino to learn, adapt and evolve over time. The intelligent modules have been tested with commercial cloud platforms. By the end of 2017, over 3, 000 Amino OSs have been deployed on the high-performance computing terminals in over 20 locations in the Asia Pacific region, providing reliable high- performance computing power for over 18 months.
 The growing team of Amino is composed of distinguished researchers and experts from top universities in New Zealand and Australia. The Amino project is supported by The New Zealand Digital Economy Development Trust, a trust that actively promotes New Zealand companies and research institutions to connect with global digital technology. The Amino
2 / 39

team combines a deep background in artificial intelligence, big data, distributed systems, information security & risk governance, economics, and blockchain with real-world business experience as entrepreneurs and technologists.
3 / 39

Table of contents
1 Executive Summary ....................................................................................................................................... 2 2 The world needs better computing infrastructure ............................................................................. 5 2.1 Weaknesses in centralised cloud technology........................................................................................................................6 2.2 Blockchain and centralised computing cloud technology ............................................................................................... 9 2.3 Demand for distributed computing........................................................................................................................................ 10 2.4 Sharing computing resources with current architectures............................................................................................ 10 2.4.1 Use cases for decentralised distributed computing ......................................................................................... 12 3.The Amino Solution ..................................................................................................................................... 14 3.1 Design Concept................................................................................................................................................................................ 15 3.1.1 Rewards based on contributions, not results...................................................................................................... 15 3.1.2 Measurement, prediction, adaptation and evolution....................................................................................... 17 3.1.3 Performance and price stability................................................................................................................................ 17 3.2 The three tiers node ecosystem ............................................................................................................................................... 17 3.2.1 Super nodes – Ledger and Intelligent Manager.................................................................................................. 18 3.2.2 Master nodes – Routing and High availability .................................................................................................... 19 3.2.3 Slave Nodes – Computation ........................................................................................................................................ 19 3.2.4 Customers (computing resource users) ................................................................................................................ 19 3.3 Amino token economy and governance ............................................................................................................................... 20 4.Amino Technology ....................................................................................................................................... 23 4.1 Sharing computing resources ................................................................................................................................................... 24 4.2 Amino OS - a hypervisor-based sharing architecture [10]........................................................................................... 25 4.3 Intelligent modules that streamline Amino performance [12] .................................................................................. 26 4.4 Amino is Empowering the real world business ................................................................................................................ 27 5 Roadmap ......................................................................................................................................................... 29 6 Token Allocation .......................................................................................................................................... 30 7 Team ................................................................................................................................................................. 31 8 Investors and Partners............................................................................................................................... 37 9 References ...................................................................................................................................................... 38
4 / 39

2 The world needs better computing infrastructure
Amino provides a unique infrastructure that both meets the growing demand for distributed computing and overcomes weaknesses of centralised cloud computing. This section describes those weaknesses and how they affect blockchain technology, followed by a discussion on the demand for decentralised distributed computing. It concludes with a description of current sharing architectures and a discussion of why those architectures can’t fulfill the demand for decentralised distributed computing.
5 / 39

2.1 Weaknesses in centralised cloud technology
Distributed computing networks are currently provided by centralised cloud technology, but there are several disadvantages of this approach:
1)HIGH COST.
In 2014, data centers were responsible for around 1.62% of the world’s utilised energy that year, according to Yole. In correlation to this percentage, total world- wide data center energy consumption is expected to reach 507.9 TWh by 2020. [1] This power is mainly used for three aspects of cloud operations: running of hard- ware, cooling of infrastructure, and maintenance of hardware. The high running cost
due to large energy consumption in a centralised cloud results in high prices for consumers of the cloud’s resources, which is certainly less competitive than alternative approaches.
Figure 1: Data Centers worldwide will have an increasing need for power [1]
2)HIGH LATENCY.
As aconsequence of their large energy consumption, cloud computing centers are generally
built in rural areas, causing high latency for consumers due to the long distance from the consumer to the resource they are respectively consuming. Cloud services need to move closer to the edge of their resource consumption - away from central data centers and nearer to the
 6 / 39

consumers. High latency can be dangerous, i.e., applications that connect things in real time, such as self-driving cars confronted with fast moving road hazards. It can also compromise the user experience - for example, in order to obtain a seamless AR or VR experience, we need networks that move data faster than we can bodily process.
Figure 2: The distribution of the participating European data centers.
Figure 2 observes the fact that the places with the greater data center densities are London, Amsterdam, Frankfurt, Paris and Milan areas and their surroundings. It will cause high latency for consumers due to the long distance from the consumer to the resource they are consuming. [2]
3)LOW RELIABILITY
Any delays in the processing of data relating to medicine or defense applications can bring
unimaginable damage to the society. For instance, one third of world’s internet data processing
depends on Amazon’ s large online data centers. Recently, Amazon’s Northern Virginia data 7 / 39
 
center disrupted in Feb 2017 which almost resulted in the entire internet services sector breaking down. [3][4] The event was triggered by human error. Human error also led to an outage of AWS’ closest com- petitor, Microsoft Azure, back in 2014. [4] In addition, deploying real-time backup of data in a cloud leads to exponentially increasing costs.
4)LIMITED SCALABILITY
The enormous number of Internet of Things (IoT) devices that will be deployed in the future
will create increasing levels of data flow and there will be huge pressure on computing networks to scale-up. The high cost of centralised cloud hardware combined with the need to send all data to the centralised system (and back) com- promise the network scalability of centralised cloud platforms. Performance and scale of centralised computing networks would hit a plateau.
5)NETWORK CONGESTION
According to Cisco Visual Networking IndexTM,The number of devices connected to IP networks
will be more than three times the global population by 2021. There will be 27.1 billion networked devices in 2021, up from 17.1 billion in 2016. [5] Annual global IP traffic will reach 3.3 ZB per year by 2021, or 278 Exabytes (EB) per month. In 2016, the annual run rate for global IP traffic was 1.2 ZB per year, or 96 EB per month. [5] However, relatively low expansion rates of network bandwidth cannot match the data’s growth. Furthermore, numerous IoT applications being deployed online at once will produce unmanageable amounts of daily data from sensors causing congestion. As a result, data processing and responses will take longer. An example is Cisco’ s jet engines, which creates about 10 terabytes of activity data in 30 minutes. Transferring this volume data to the cloud, and receiving the results of data processing, requires substantial network bandwidth, takes significant amounts of processing time and can have delays.
6)INFORMATION SECURITY
There are certain information security risks present in a centralised network. Physical attack,
terminal counterfeiting, resource-depletion, Denial of Service (DoS) attacks, and node control are all threats to a user’ s privacy. After the revelations of Edward Snowdon, centralised systems which rely on third-party institutions for security guarantees have lost users’ trust even though information security is key in today’ s data rich environment.
One recent technology that enables decentralised applications is blockchain. Next, we discuss how blockchain has become more reliant on centralised cloud, which diminishes the benefits of
8 / 39

decentralisation. However, decentralisation is critical for the distributed computing networks of the future, so an alternative approach is needed.
2.2 Blockchain and centralised computing cloud technology
Blockchain technology has developed rapidly over the last few years. Blockchain is a type of decentralised technology by design. However, most blockchain projects depend on centralized cloud computing as follows:
1)The accounting system runs on a decentralised system, but decentralised apps (DApps) are deployed to centralised cloud servers. In the case of many DApps based on the popular
blockchain platforms Ethereum (ETH) and Bitcoin (BTC), only the transaction information and the core data are packed into a block and stored in ETH and BTC mining servers. The application itself, and other digital information required/produced by the app, still rely on centralised cloud computing or servers built by the application team and deployed in a centralised data center.
2)Most mining machines are built up and managed by private institutes. During Bitcoin’s early days, anyone could“mine”it using their home computer. But as the price of digital currency
climbed towards $100 in 2013, professional mining institutes emerged. Today, these institutes, or pools have become concentrated. This means blockchain’s blocks belongs to centralised institutions with centralised computing resources. An article in Quartz shows Bitmain may now be the most influential company in the Bitcoin economy by virtue of the sheer amount of processing power, or hash rate, that it controls. Its mining pools, Antpool and BTC.com, account for 28.9% of all the processing power on the global bitcoin net- work. [6]
This reliance on centralised computing infrastructure means that blockchain appli- cations cannot realise the true benefits of decentralisation. The weaknesses of centralised cloud (see §2.1) still compromise the performance of decentralised applica- tions. Instead, blockchain applications should utilise distributed computing that uses decentralised sharing of computing resources. With the arrival of 5G, in addition to blockchain, more businesses will move their services and data from centralised cloud to distributed computing networks in order to increase efficiency and cut costs.
9 / 39

2.3 Demand for distributed computing
“By 2023, 5th generation mobile (5G) will make up around one-fifth of all mobile data traffic, with subscriptions forecast to reach 1 billion” [7]. 5G also has the potential to realise hundreds of billions of dollars in industrial and business revenue, and further in the future-real-time mobile connectivity will enable connected cars, advanced machine intelligence, and blended virtual/physical realities [2]. However, in order to realise the potential of 5G, a new kind of computing network is needed. Distributed computing networks that provide computing, storage, and processing re- sources in the right place at the right time will benefit 5G use cases in particular. These networks need to have low latency, enhanced security, resilience, scalability and efficiency, i.e., the networks need to execute computing tasks (large or small) at a much lower cost than that of current cloud computing or super computing resources. By utilising these networks, businesses such as:
a. Smart manufacturing;
b. Automotive;
c. Media and content delivery;
d. Virtual reality (VR)/augmented reality (AR);
e. Artificial Intelligence (AI) and data analytics;
f. Data storage and analytics with regulatory compliance;
can benefit from 5G technology. These types of use cases account for 25% of the $619 billion 5G business potential estimated for 2026 [7].
Distributed computing networks need to span end-devices, edge sites, distributed sites, central sites, and public clouds. They require a software-defined infrastructure and a network that are both capable of managing the complexity and demands of this distributed environment. Before discussing Amino’s innovative distributed computing network, we will discuss the reason why currently no solution can meet the rising demand for distributed computing networks.
2.4 Sharing computing resources with current architectures
Current decentralised architectures use distributed computing networks to share computing resources, but the mechanisms for sharing resources leads to poor experiences for both
10 / 39

contributors and consumers of those resources. The architectures currently used fall into one of two categories:
1)Deployment of separate cloud computing centers to cover all areas. In essence, computing resources are still centralised in cloud data centers, but this architecture provides some benefits by being closer to the edge of resource consumption. However, consumers of computing resources still suffer from many of the disadvantages described in §2.1. The high latency issue is resolved and the high congestion issue is mitigated, but high cost and information security issues remain the same. Also, the issues of low reliability and limited scalability are exacerbated as computing is provided from a cloud center in a single region. Contributors of computing resources also suffer under this architecture because individuals or small providers are excluded from this architecture, only corporate giants like AWS and Google can participate.
2)Use of blockchain to link individual computing resources. Blockchain applications enables individuals to share computing resources, e.g., data in the form of digital media. However, this architecture has serious disadvantages for both consumers and contributors:
a. CONTRIBUTORS can provide their computing resource, but it is difficult for individuals to guarantee stability. If their computing resource fails in the middle of executing a task, they will receive no payback at all even though their resources were utilized until the point of failure.
b. CONSUMERS also suffer in the failure scenario. They have an agreement with the contributor to reward them for successful execution, so when the execution fails they do not have to reward the contributor and can find another, hopefully more reliable, shared resource. However, they have wasted precious time waiting for the initial resource to fail,even if the next resource is successful.
The lack of a concrete value model for contributors and stability for consumers indicates that this architecture is based on the wrong economic model.
In both of the architectures described here, the experience for both contributors and consumers of computing resource is compromised. Separate cloud centers suffer from many of the same problems as centralised clouds, so the underlying architecture is not the right approach. For blockchain applications, the sharing architecture is correct, but the economic model is wrong.
11 / 39

2.4.1 Use cases for decentralised distributed computing
Two use cases highlight the fact that the current economic model for decentralised distributed computing needs to be changed:
1)Financial trading application for personal trading that utilises AI/Machine Learning (ML) techniques.
This application requires significant computing resources, but not tightly coupled resources that are present in high performance computing architectures. Rather what is required, is a flexible pool of computing resources that can be expanded or contracted depending on the number of application users. In addition, this pool of resources doesn’t need to provide guarantees for any individual computing resource, but it needs to guarantee the timely completion of tasks executed on the pool. Performing these calculations on a decentralised distributed computing network enables task to be executed on nearby resources ensuring timely completion. In addition, an economic model that rewards completion by the pool of resources incentivises the network appropriately.
2)Compute-as-a-Service for educational institutions.
Educational institutions have periodic demand trends and these trends mean that decentralised distributed computing can spread the workload across high and low demand periods. In mid- semester and near the end of semester many educational institutions have a high demand on their computational resources from STEM courses and/or from media-related courses, e.g., courses requiring video-editing.
During these periods an institution could utilise decentralised distributed com- puting, with the benefits of edge computing, to satisfy peak demand periods. However, during summer, educational institutions have excess computing re- sources which could be contributed to the decentralised distributed computing network as “payment” for using computing resources during the peak period. This enables the institution to smooth its demand pattern and not only “burst” into the distributed computing network during high demand times but offset that use during low demand periods.
Amino provides a blockchain application for sharing computing resources, but with an economic model that ensures benefits for both contributors and consumers. In- dividual contributors are
12 / 39

rewarded by Amino on the blockchain for making their computing resources available, regardless of successful execution of tasks. Amino provides performance guarantees to consumers by ensuring that their tasks will be executed by any of the available computing resources within Amino. They pay Amino on the blockchain for ensuring their task execution is completed in a timely manner. This fundamentally different economic model underpins Amino and enables Amino to build the infrastructure and network to provide a distributed computing network for the future.
The Amino Ecosystem will be described next, followed by the technology behind Amino.
13 / 39

3.The Amino Solution
Just as amino acids form the essential building blocks of the human body and a vita energy source for each cell, Amino will provide a next generation, decentralised in- frastructure that transforms computer resources into digital assets. The Amino ecosystem consists of a three tier computing architecture that utilises a novel OS and is managed by token system.
14 / 39

3.1 Design Concept
The goal of Amino is to optimally connect and manage idle computing resources from the world’s computers and form a stable, distributed computing network that supports a wide range of applications. Amino will achieve this goal by developing an innovative decentralised architecture to support a distributed computing network and in the process, utilise blockchain to convert idle computing resources into digital assets. The Amino ecosystem design creates a fair, flexible, and reliable ecosystem.
3.1.1 Rewards based on contributions, not results
In order to accept requests for tasks that require computing resources from hun- dreds of thousands of businesses, the Amino architecture needs to have enough ca- pacity to handle these requests. Unlike the conspiracy trading market behind Golem [8] and SONM [9], the pure peer-to- peer (P2P) matching market does not have a large-scale effect. Distributed systems can organise a large number of computing re- sources to work together, so Amino has revolutionised the organisation system (i.e., the governance structure) by providing a decentralised, distributed network that is responsible, as a whole, for completing requested tasks. Resource providers are simply responsible for contributing their resources to Amino which creates a fair reward system and encourages providers to share their idle computing resources. Amino will determine how to best utilise the resources.
15 / 39

 Figure 3: In Amino, the platform takes responsibility for overall tasks, individual nodes provide computing resources to the platform.
Figure 4: But other platforms, individual nodes take responsibility for a specific task (peer-to- peer), the platform matches and assigns the task.
 16 / 39

3.1.2 Measurement, prediction, adaptation and evolution
Any system that provides large-scale commercial applications must have the ability to self-learn and evolve in order to maintain its robustness. Amino will measure both the arrival of task requests and the completion of tasks on the Amino block- chain in order to understand the demand for computing resources, as well as how the supply of these resources results in task completion. A simple Proof-of-Work (PoW) backbone cannot provide an accurate record of task requests and completion for a large decentralised network. Therefore, we use a combination of Multisignature/Byzantine Fault Tolerance (BFT) and Delegated Proof of Stake (DPoS) as a con- sensus mechanism for the Amino blockchain, thus providing a scalable way to record task requests and completion. The records on the Amino blockchain can then be used as input to AI/ML methods in order to predict both the location and profile of future requests. These predictions can, in turn, be used to adapt the way in which tasks are allocated to computing resources in order to maintain Amino’ s high performance across changing workloads. Finally, the prediction and adaptation approaches can be used as inputs to an evolution process that determine the configuration and location of computing resources to add to Amino in order to best provide high performance distributed computing.
3.1.3 Performance and price stability
Amino provides stability of both performance and price by adapting the way that available computing resources are used to meet requests for computing tasks. Amino will provide a variety of options for computing resource configurations (CPU cores, GPU graphics card, RAM memory, storage space) and provide prices for those configurations. By efficiently meeting demand for computing resources (from re-quested tasks) and looking ahead to determine the future value of computing re- sources, Amino will leverage market forces to keep performance stable (by incentivising the contribution of computing resources before they are needed) and price stable (by creating competition to provide computing resources via incentives).
3.2 The three tiers node ecosystem
Amino utilises a three tiers computing structure as shown in Figure 5. In this subsection, each tier of the structure is described in detail.
17 / 39

 Figure 5: The Amino 3 tiers computing structure
3.2.1 Super nodes – Ledger and Intelligent Manager
The super node allocates requests for computing tasks to the Amino. These nodes control the entire Amino and its reward system. They utilise a low-delay blockchain to record transactions:
1)the allocation of a request to a computing resource; and 2)the return of the result from a completed request.
18 / 39

Super nodes can instantly find the required computing resources needed to complete the associated task by auditing the statistics from the master node such as: the performance and specifications of the master node’s slave nodes, the net- work status of the master node and its slave nodes, etc. Once the customer confirms their request for computing resources, the super node allocates a master node as the customer’ s interface by identifying the best master node according to avail- able computing unit resources of all the master nodes. The designated master node provides the requested resources for the specified time to complete the task.
3.2.2 Master nodes – Routing and High availability
Master nodes provide high available computing resources and are responsible for the routing of their associated slave nodes. They also record the statistics of these computing resources so that they can provide this information to the super nodes when super nodes are allocating tasks. Once a super node has assigned a customer’ s task to a master node, that master node provides an interface for that customer’ s task and schedules that task to the master node’s slave nodes in a way that ensures efficient performance. Once the request is complete, the master node returns the result of the task to the customer and notifies the super node (that originally as- signed the task to the master node) that the task is complete.
3.2.3 Slave Nodes – Computation
Slave nodes are computation nodes that have been contributed to Amino in order to provide idle computing resources. When a master node distributes a customer’s task to a computing unit, the unit downloads the task information from that master node, provides the computing resources requested, and transmits task result back to the master node. Slave nodes become idle when they are not being used by their owner and have not been assigned any tasks by Amino. At that point the unit will automatically send proof that it is online and also provide it’s working capabilities to the master node.
3.2.4 Customers (computing resource users)
Customers will request a configuration of computing resources from Amino according to their needs (CPU cores, GPU graphics card, RAM memory, storage space). Once their request has been assigned to a master node, they will interface with that node to upload their task information and download the result(s) of the task from the same interface. Both the upload and download transactions will be recorded on the appropriate super node. The entire engagement will be governed by a smart contract and once the download is complete, the contract execution is also completed.
19 / 39

3.3 Amino token economy and governance
Amino Network is a two token ecosystem consist of: AMIO token and FOG token. AMIO token operates on a governance level, provides token velocity and used as a payment method, while FOG token belongs to a contribution side it is not tradable nor transferable. Token ecosystem structure is described in detail below.
AMIO token provides decentralised governance on the Amino network through:
- Ecosystem management. AMIO represents voting rights, holders of AMIO are eligible of electing management units like Super nodes, Master nodes on the basis of Delegated-Proof- of-Stake (DPoS) consensus.
- Bonding. AMIO token allows to build up a strong “binding” relationship within three tiers of the network nodes. The amount of pledges is periodically adjusted by AI according to Amino network size.
To become eligible Super Nodes, contributors have to lock up a defined amount of AMIO token, this signals as a guarantee that the super node owner is a trustable network actor and accept rules and regulations of the network. After Super Node is elected by AMIO holders, bonding imposes responsibilities on super node for ensuring appropriate behavior of its associated master and slave nodes.
Master Nodes have to lock up AMIO tokens as well to become eligible actors, which will guarantee trusted behavior and ensure proper performance of associated slave nodes. Build-up application actors. PaaS, SaaS, and DApp built up on Amino Network have to lock up AMIO tokens to connect to Amino API, where lock-in amount depends on the time required for API usage.
- Payment and Income distribution. AMIO token is used as a means of payment for using Amino Cloud-Edge Services to complete computational tasks.
- Investment and Management Contribution. AMIO holders have the right to receive network income if they meet certain criteria: lock minimum amount of AMIO token for a time period.
       20 / 39

AMIO governance will be determined by Artificial Intelligence. For example: lock amount and period for certain purpose
FOG token used as a measure of participation in the network vitality, it is based on the Proof- of-Contribution concept (PoC), therefore FOG tokens are not tradable nor transferable between the actors, it is generated according to the contribution. Amount of FOG Tokens reflects the scale of contribution to computing resources and investments of Amino Network.
- Providers of computing resources earn FOG Token according to performance. FOG Token is generated periodically (hourly) based on the node performance, position in the network, and duration of the contribution. Earning are dynamically defined by analysis of the entire network and predictions of future dynamics conducted by intellectual governance system. Providers have to link their wallet with corresponding nodes to receive FOG accordingly.
- Investment and management contributors earn FOG Tokens for lock-ups. As a proportional allocation, equivalent 1/9 of the total FOG generated by computing nodes will be distributed to the AMIO token holders who locked up AMIO tokens for the required period of time in their wallets.
FOG Token burns once redeemed by contributors as a periodical distributed revenue in the period. Moreover, FOG Tokens cannot be traded on any exchanges or transferred between users.
Keynesian economic theory
Keynesian economic theory proposes that spending boosts aggregate output and generates more income, so as for Amino Network ecosystem. In the early stage of economic development, an injection in the form of investments into infrastructure eventually will lead to boost network activity and even more network expansion. Amino ecosystem connects both demand and supply side with AI intermediary that balance the boom and low tides:
- The demand side is represented by Amino ecosystem together with PaaS, SaaS service providers, computing resource providers, and consumers who need computing task execution;
  21 / 39

- The supply side is provided through Amino public computing infrastructure on a public chain, that connects computing nodes include lots of idle computing resource which make the network cost very competitive;
- Amino is very much like a “exporting orientated” economy – providing service to the real world business
- With data and technology, the adjustment of economic policy in a blockchain economy is more effective and controllable than that in a real economy;
- 30% of the AMIO token will be invested into Amino Network Infrastructure by Jan 2020. Using big data analysis and smart contract for building smart network infrastructure and ecosystem will stimulate business opportunities within Amino Network.
22 / 39

4.Amino Technology
Amino enables idle computing resources to be shared via a decentralised, distributed computing network.
This section discusses the underlying technology behind Amino.
23 / 39

4.1 Sharing computing resources
In any system that shares computing resources the needs of the users that are as follows:
1)The user that is sharing their computing resource (the contributor) needs:
a. their normal computing use to be unaffected by the sharing, i.e., no reduction in performance, no increased probability of system failure ( “blue screen of death” ); b. the use of peripherals to be unaffected by the sharing architecture;
c. their data to be secure;
2)The user that is consuming the shared computing resources (the consumer/ customer) needs:
a. easy-to-use, reliable computing resources; b. their data to be secure.
Amino enables the sharing of computing resources, so the contributor won’t experience any reduction in performance. This is because their resources will not be idle when they are using them, hence won’ t be shared at that point in time. In this case, the sharing technology must not increase the probability of system failure, enable the use of peripherals as usual, and keep both the contributor’ s and the customer’ s data secure. Amino OS, described in the next section, meets all of these needs. When combined into a decentralised network in Amino, the other customer needs, i.e., easy-to-use, reliable computing resources are also supplied, as described in §3.3.
 24 / 39

4.2 Amino OS - a hypervisor-based sharing architecture [10]
Amino OS is a more secure, stable and efficient architecture for computing. Amino OS is a “bare bones” hypervisor (KVM) that is installed on a machines, e.g., PCs, smart phones, IoT devices, and used to create side-by-side virtual machines (VMs), also supports Docker and WASM. The first VM contains the usual operating system that provides a personal computer (PC) for the owner of the physical machine. The second VM is a computing unit for Amino. The two VMs share the physical machine’ s resources, but the computing unit will only declare itself available when the PC VM is idle. By using two separate VMs, Amino OS ensures may of the needs of both the Amino contributor (i.e., the physical machine owner) and the Amino customer, namely:
1) the VMs themselves should not increase the chance of system failure as they only interact through the hypervisor. Amino OS is based on a mature hypervisor (KVM) with good support for the usual OS present on a PC, i.e., Windows, Linux, Mac. If the contributor wanted to use an unusual OS for their PC, then this stability may be compromised;
2) Amino OS enables the use of peripherals by VMs as usual, although the computing unit VM will limit its interaction to fundamental computing resources, i.e., CPU, GPU, RAM, and storage;
3) both the contributor’ s and the customer’ s data are isolated from each other within their respective VMs. As long as each of the VMs is secured against data breaches, then each data will be secure.
25 / 39

 Figure 6. The structure of Amino OS
4.3 Intelligent modules that streamline Amino performance [12]
Amino will have embedded intelligent modules to streamline the sharing of computing resources. These modules will integrate the innovative hypervisor-based OS and the decentralised computing network that helps run Amino, and will enable Amino to learn, adapt and evolve over time. Amino’s learning, adapting and evolving characteristics will ensure that it always operates at a high performing level even as the volume of requests for computing resources increases. The key functionality of Amino’s intelligent modules is as follows:
1)Intelligent modules will leverage information from blockchain records to measure both demand for resources and the performance of nodes (as described in §3.1.2);
2)AI and/or ML will predict future demand and performance;
3)Predictive models will inform optimisation of task assignment to master nodes/slave nodes;
a. Online algorithms will be tuned by sophisticated offline optimization approaches;
b. Amino will self-tune/dynamically adapt to future workloads;
4)Optimisation will also be used to evolve Amino by investigating the effect of, for example, adding extra computing resource capacity in specific locations.
26 / 39

By learning, adapting, and evolving via its intelligent modules, Amino will continue to provide efficient, high performan computing to meet future demand.
4.4 Amino is Empowering the real world business
 Amino is not just a concept, it has already started empowering the real-world business:
 Over 4, 000 nodes in 20 locations around the Asia Pacific region connected to Amino for 3
years;
 Amino application block for AI Deep learning Cloud platform was launched in 2018. 10,000
registered users from top Universities research Labs;
 In March 2019, signed 15 million USD contract using Amino AI power and Cloud-edge IaaS
services.
 Hybrid Cloud
US$ 10 Million
Signed Over US$ 10 Million contract with fortune global 500 companies Already US$2 Million $2 million in services have been delivered
IoT
US$ 5 Million
Signed US$ 5 Million contract in March 2019 provide IoT and AI server for logistics
 27 / 39

 AI learning cloud platform
10x Cheaper & 10,000 AI Engineer Registers
Over 10,000 registered users include top university students, researchers and AI Engineers
Cloud-edge computing
1,000 AI edge nodes
Setting up 1,000 edge computing for textile AI defect recognition by 2020
 28 / 39

5 Roadmap
 29 / 39

6 Token Allocation
Total AMIO tokens = 1,000,000,000
Allocation Release Amount Release Release Note
     Date
Schedule
 IEO 5%
   50,000,000 AMIO
    40% unlock
30% release on 60 days
30% release on 90 days
     Early Investors
10%
  100,000,000 AMIO
 July 1, 2019
   Gradually release in 5 months
      Network Infrastructure 25%
 250,000,000 AMIO
 Jan 1, 2020
   Gradually release in 10 months
  Building commercial infrastructure for Amino network, such as backbone bandwidth, AI edge nodes
    Team 20%
  200,000,000 AMIO
  May 1, 2020
    Gradually release in 24 months
   Founders and team
   Trust (Foundation)
20%
 200,000,000 AMIO
Oct 1, 2019
  Gradually release in 24 months
 Funding for universities in fundamental research and development
   Community 20%
   200,000,000 AMIO
  May 1, 2019
    Gradually release in 20 months
   Partnerships and Ecosystem
  Total 100% 1,000,000,000 AMIO
     30 / 39

7 Team
The Amino team is composed of the world-leading researchers and experts from top universities in New Zealand and Australia.It combines a deep background an artificial intelligence, big data, distributed systems, information security & risk governance, economics and blockchain, with real-world business experience as entrepreneurs and technologists.
The Amino project is supported by The New Zealand Digital Economy Development Trust that actively promotes New Zealand companies and research institutions to connect with globe digital technology.
31 / 39

Founders/ Scientists
Dr. Michael O’Sullivan
Co-founder / CTO / PhD Stanford
Assistant Professor in University ofAuckland
Operations research expert dedicated to research in the field of
intelligent cloud computing
 Specialises in the field of Operations Research (OR) with Analytics.
 Utilises his area of expertise to develop intelligent systems in cloud
computing.
 Formed ORUA – research group specialising in utilising OR and Analytics to develop intelligent systems.
Professor Cameron Walker
Co-Founder / Chief Scientist,
Associate Professor in University of Auckland
 Main research area involves computational analytics.
 Specialises in building models that make use of system measurements to understand the dynamics of the systems as well as system performance.
Dr. Felix Shu Xia
Co-Founder/Trustee
DBA (Doctorial of Business and Administration) / Serial Entrepreneur
 Over 30 years of business experience in IT, environmental
technologies and medical equipment.
 Founder of “Suntech Group”, the third largest domestic security company in New Zealand
 Founding General Manager of “The University of Auckland Innovation Institute (China) ”
   32 / 39

Sample Publications:
 A Malik, C Walker, M O’Sullivan, O Sinnen(2018). Satisfiability modulo theory (SMT)
formulation for optimal scheduling of task graphs with communication delay. Computers &
Operations Research 89, 113-126.
 Hamling, I., O'Sullivan M, Walker, C., & Thielen, C. (2015). Improving Resource Efficiency in
Internet Cafes by Virtualization and Optimal User Allocation. Paper presented at IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC), Limassol, CYPRUS. 7 December - 10 December 2015. 2015 IEEE/ACM 8TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD COMPUTING (UCC). (pp. 9).
 Harton, T. W., Walker, C., & O'Sullivan M (2015). Towards power consumption modeling for servers at scale. Paper presented at IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC), Limassol, CYPRUS. 7 December - 10 December 2015. 2015 IEEE/ACM 8TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD COMPUTING (UCC). (pp. 7).
R&D Team
Dr. Isaac Hamling
Distributed Storage System Architect
PhD
 Received his Doctor of Philosophy (PhD) in Engineering Science in 2016, producing his thesis in relation to Intelligent Tiering for Cloud Storage.
 His research work is based largely on cloud computing. He has produced the publication Improving Resource Efficiency in Internet Cafes by Virtualization and Optimal User Allocation (2015).
Dr. Reza KhaleghParast
Research & Engineer – Cryptography and Security
PhD
 Specialises in Security and Data Protection.
 Professional member of ISACA (international professional association focused on IT Governance) and IEEE (Institute of Electrical and Electronics Engineers).
  33 / 39

 Dr. David Airehrour
Research & Engineer – Cryptography and Security
PhD
 Specialises in Security and Data/Network Protection.
 Produced the publication A Trust-Aware RPL Routing Protocol to
Detect Blackhole and Selective Forwarding attacks (2017).
Dr. Tim Harton
Distributed System Architect PhD
 Specialises in cloud computing and system management.
 Produced the publication Towards power consumption modeling for
servers at scale (2015).
Operations Team
Kristina Shalygina
CMO
Master of Finance
 Co-Leader of Fudan Blockchain Association
 Analyst of Ministry for Economic Development of the Russian Federation
Hanyang Xia
Operations Analyst
years of experience in general business operation analytics
Global work experience in Australasia, Asia and Europe.
Received his Bachelor of Commerce at the University of Auckland in 2014.
   34 / 39

 Wilson Huang
Talent Acquisition Manager
Master of Business Administration (M.B.A) from The University of Auckland in 2018.
Has a strong, reputable and established talent pool.
Andrew Hughes
Operations Analyst
Received his Bachelor of Commerce at the University of Auckland in 2015.
6 years work experience in financial sectors.
The New Zealand Digital Economy Development Trust
Chris Linton
Trustee
Lawyer,Partner at Duncan Cotterrill
Committee of the blockchain Association of New Zealand Specialist-corporate commercial, M&A, governance, infrastructure and blockchain, digital, fintech, gaming
President of the New Zealand Scandinavian Business Association
  35 / 39

Arron Judson
Trustee
Commercialisation Specialist
General Manager of Marketing and Partnerships at Scion(a New Zealand’s National Crown Research Institutes)
Chair of Scion’s Commercialization Committee
Innovation Manager at the University of Auckland for 5 years
25 years of senior management roles at Toshiba and Ericsson.
Murray Brewer Trustee/Partner at Grant Thornton
Over 20 years of experience in tax consulting at PwC and Grant Thonton
Specialist experience in New Zealand’s international tax rules including blockchain.
  36 / 39

8 Investors and Partners
 37 / 39

9 References
[1] Yole Développement(2015). New Technologies and Architectures for Efficient Data Center [Market & Technology Report 2015], Retrieved July, 2015:
[2] P. Bertoldi, M. Avgerinou, L. Castellazzi, Trends in data centre energy consump- tion under the European Code of Conduct for Data Centre Energy Efficiency, EUR 28874 EN, Publications Office of the European Union, Luxembourg, 2017, ISBN 978-92-79-76445-5, doi: 10.2760/358256, JRC108354
[3] Jacob Kastrenakes(2017). Amazon’ s web servers are down and it’s causing- trouble across the internet[Online article], Retrieved 28 February, 2017, from The Verge: https://www.theverge.com/2017/2/28/14765042/amazon-s3-outage-causing-trouble
[4] Jordan Novet(2017). AWS apologizes for February 28 outage, takes steps to pre- vent similar events[Online article], Retrieved 2 March, 2017, from VentureBeat: https://venturebeat.com/2017/03/02/aws-apologizes-for-february-28-outage-takes-steps- to- prevent-similar-events/
[5] Cisco Visual Networking IndexTM (2017), The Zettabyte Era: Trends and Analy- sis [Technical Report2017], Retrieved June 2017, from Cisco System Inc: https://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking- index-vni/vni-hyperconnectivity-wp.html
[6] Joon Ian Wong(2017). China’s Bitmain dominates bitcoin mining. Now it wants to cash in on artificial intelligence [Online article], Retrieved 20 August, 2017, from Quartz: https://qz.com/1053799/chinas-bitmain-dominates-bitcoin-mining-now-it-wants-to-cash- in-on- artificial-intelligence/
[7] Martensson, L. (2018). Distributed Cloud Will Unlock the Power of 5G [Online article]. Retrieved 6 June, 2018, from Techonomy: https://techonomy.com/2018/05/distributed-cloud- will-unlock-power-5g/
[8] Golem (2018). [Website]. Retrieved 6 June, 2018, from golem.network: https://golem.network/
[9] SONM (2018). [Website]. Retrieved 6 June, 2018, from sonm.com: https://sonm.com/
[10] Amino (2018). Amino OS: effective sharing of computing resources for decentralised computing[White paper].
[11] Amino (2018). Amino: an innovative decentralised ecosystem for high perfor- mance distributed computing [White paper].
38 / 39

[12] Amino (2018). Intelligent Decentralised Distributed Computing: Intelligent cloud principles and techniques streamline the performance of Amino, an in- novative decentralised distributed computing network [White paper].
39 / 39
",,,,
,,,,
,,,,
,,,,
,,,,
,,,,